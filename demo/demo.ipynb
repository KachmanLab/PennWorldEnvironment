{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import pen_world\n",
    "from PPO import PPO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in sub environment: 256\n",
      "max_ep_length: 512\n"
     ]
    }
   ],
   "source": [
    "initialization_radius = 10  # radius of initialization positions (all agent initializations are done n steps from env center)\n",
    "env = gym.make('PenWorld-v0', n=initialization_radius)\n",
    "state_dim = 2  # state is given by 2D x,y coordinates\n",
    "action_dim = 27  # total action space of all positions\n",
    "lr_actor = 0.0001  # learning rate for actor\n",
    "lr_critic = 0.0003  # learning rate for critic\n",
    "gamma = 0.99  # discount factor\n",
    "K_epochs = 8  # update policy for K epochs\n",
    "eps_clip = 0.2  # clip parameter for PPO\n",
    "has_continuous_action_space = False  # discrete action space\n",
    "update_timestep = env.max_ep_length * 4  # update policy every n timesteps\n",
    "max_ep_length = env.max_ep_length  # max timesteps in one episode\n",
    "variable_action_space = True  # variable action space (action space is different for each state)\n",
    "device = 'cpu'  # can be set to 'cpu' or 'cuda'\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, device=device, variable_action_space=variable_action_space)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Agent\n",
    "Agent trained for 5000 episodes so that it can learn to reliably find the reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      "took 0.0008790493011474609 s\n",
      "episode: 100\n",
      "took 9.389660120010376 s\n",
      "average reward: 0.65\n",
      "episode: 200\n",
      "took 5.688010931015015 s\n",
      "average reward: 0.83\n",
      "episode: 300\n",
      "took 5.81580114364624 s\n",
      "average reward: 0.82\n",
      "episode: 400\n",
      "took 4.447878122329712 s\n",
      "average reward: 0.91\n",
      "episode: 500\n",
      "took 4.514321804046631 s\n",
      "average reward: 0.87\n",
      "episode: 600\n",
      "took 3.6592791080474854 s\n",
      "average reward: 0.95\n",
      "episode: 700\n",
      "took 2.1819028854370117 s\n",
      "average reward: 0.99\n",
      "episode: 800\n",
      "took 3.2711286544799805 s\n",
      "average reward: 0.95\n",
      "episode: 900\n",
      "took 2.6075358390808105 s\n",
      "average reward: 0.97\n",
      "episode: 1000\n",
      "took 2.9943387508392334 s\n",
      "average reward: 0.98\n",
      "episode: 1100\n",
      "took 1.8115880489349365 s\n",
      "average reward: 1.0\n",
      "episode: 1200\n",
      "took 1.8829848766326904 s\n",
      "average reward: 0.98\n",
      "episode: 1300\n",
      "took 1.2746479511260986 s\n",
      "average reward: 1.0\n",
      "episode: 1400\n",
      "took 1.3750219345092773 s\n",
      "average reward: 1.0\n",
      "episode: 1500\n",
      "took 1.629776954650879 s\n",
      "average reward: 0.99\n",
      "episode: 1600\n",
      "took 1.231034278869629 s\n",
      "average reward: 0.98\n",
      "episode: 1700\n",
      "took 1.132223129272461 s\n",
      "average reward: 1.0\n",
      "episode: 1800\n",
      "took 1.1771199703216553 s\n",
      "average reward: 1.0\n",
      "episode: 1900\n",
      "took 1.1322522163391113 s\n",
      "average reward: 1.0\n",
      "episode: 2000\n",
      "took 1.2003021240234375 s\n",
      "average reward: 0.99\n",
      "episode: 2100\n",
      "took 1.005051851272583 s\n",
      "average reward: 1.0\n",
      "episode: 2200\n",
      "took 1.089900016784668 s\n",
      "average reward: 1.0\n",
      "episode: 2300\n",
      "took 1.0181446075439453 s\n",
      "average reward: 1.0\n",
      "episode: 2400\n",
      "took 1.2043471336364746 s\n",
      "average reward: 1.0\n",
      "episode: 2500\n",
      "took 0.70796799659729 s\n",
      "average reward: 1.0\n",
      "episode: 2600\n",
      "took 1.0139567852020264 s\n",
      "average reward: 1.0\n",
      "episode: 2700\n",
      "took 0.7330329418182373 s\n",
      "average reward: 1.0\n",
      "episode: 2800\n",
      "took 1.0221960544586182 s\n",
      "average reward: 1.0\n",
      "episode: 2900\n",
      "took 0.7197539806365967 s\n",
      "average reward: 1.0\n",
      "episode: 3000\n",
      "took 0.9377870559692383 s\n",
      "average reward: 1.0\n",
      "episode: 3100\n",
      "took 0.7659261226654053 s\n",
      "average reward: 1.0\n",
      "episode: 3200\n",
      "took 0.9703240394592285 s\n",
      "average reward: 1.0\n",
      "episode: 3300\n",
      "took 1.0658857822418213 s\n",
      "average reward: 1.0\n",
      "episode: 3400\n",
      "took 0.6764280796051025 s\n",
      "average reward: 1.0\n",
      "episode: 3500\n",
      "took 0.6729753017425537 s\n",
      "average reward: 1.0\n",
      "episode: 3600\n",
      "took 0.8166050910949707 s\n",
      "average reward: 1.0\n",
      "episode: 3700\n",
      "took 0.6235089302062988 s\n",
      "average reward: 1.0\n",
      "episode: 3800\n",
      "took 0.5619289875030518 s\n",
      "average reward: 1.0\n",
      "episode: 3900\n",
      "took 0.6900689601898193 s\n",
      "average reward: 1.0\n",
      "episode: 4000\n",
      "took 0.5704457759857178 s\n",
      "average reward: 1.0\n",
      "episode: 4100\n",
      "took 0.642247200012207 s\n",
      "average reward: 1.0\n",
      "episode: 4200\n",
      "took 0.9377951622009277 s\n",
      "average reward: 1.0\n",
      "episode: 4300\n",
      "took 0.5929241180419922 s\n",
      "average reward: 1.0\n",
      "episode: 4400\n",
      "took 0.5883052349090576 s\n",
      "average reward: 1.0\n",
      "episode: 4500\n",
      "took 0.7081859111785889 s\n",
      "average reward: 1.0\n",
      "episode: 4600\n",
      "took 0.585686206817627 s\n",
      "average reward: 1.0\n",
      "episode: 4700\n",
      "took 0.6172831058502197 s\n",
      "average reward: 1.0\n",
      "episode: 4800\n",
      "took 0.6804769039154053 s\n",
      "average reward: 1.0\n",
      "episode: 4900\n",
      "took 0.6380629539489746 s\n",
      "average reward: 1.0\n",
      "episode: 5000\n",
      "took 0.5893290042877197 s\n",
      "average reward: 1.0\n",
      "episode: 5100\n",
      "took 0.6493120193481445 s\n",
      "average reward: 1.0\n",
      "episode: 5200\n",
      "took 0.5401136875152588 s\n",
      "average reward: 1.0\n",
      "episode: 5300\n",
      "took 0.6331017017364502 s\n",
      "average reward: 1.0\n",
      "episode: 5400\n",
      "took 0.664992094039917 s\n",
      "average reward: 1.0\n",
      "episode: 5500\n",
      "took 0.6652758121490479 s\n",
      "average reward: 1.0\n",
      "episode: 5600\n",
      "took 0.6302525997161865 s\n",
      "average reward: 1.0\n",
      "episode: 5700\n",
      "took 0.6262099742889404 s\n",
      "average reward: 1.0\n",
      "episode: 5800\n",
      "took 0.5402600765228271 s\n",
      "average reward: 1.0\n",
      "episode: 5900\n",
      "took 0.28757214546203613 s\n",
      "average reward: 1.0\n",
      "episode: 6000\n",
      "took 0.6134908199310303 s\n",
      "average reward: 1.0\n",
      "episode: 6100\n",
      "took 0.5921227931976318 s\n",
      "average reward: 1.0\n",
      "episode: 6200\n",
      "took 0.5890088081359863 s\n",
      "average reward: 1.0\n",
      "episode: 6300\n",
      "took 0.5935571193695068 s\n",
      "average reward: 1.0\n",
      "episode: 6400\n",
      "took 0.49356698989868164 s\n",
      "average reward: 1.0\n",
      "episode: 6500\n",
      "took 0.5720949172973633 s\n",
      "average reward: 1.0\n",
      "episode: 6600\n",
      "took 0.2656428813934326 s\n",
      "average reward: 1.0\n",
      "episode: 6700\n",
      "took 0.58673095703125 s\n",
      "average reward: 1.0\n",
      "episode: 6800\n",
      "took 0.5642459392547607 s\n",
      "average reward: 1.0\n",
      "episode: 6900\n",
      "took 0.5413451194763184 s\n",
      "average reward: 1.0\n",
      "episode: 7000\n",
      "took 1.1425552368164062 s\n",
      "average reward: 1.0\n",
      "episode: 7100\n",
      "took 0.988121747970581 s\n",
      "average reward: 1.0\n",
      "episode: 7200\n",
      "took 0.6773428916931152 s\n",
      "average reward: 1.0\n",
      "episode: 7300\n",
      "took 0.7433900833129883 s\n",
      "average reward: 1.0\n",
      "episode: 7400\n",
      "took 0.23794293403625488 s\n",
      "average reward: 1.0\n",
      "episode: 7500\n",
      "took 1.2672529220581055 s\n",
      "average reward: 1.0\n",
      "episode: 7600\n",
      "took 1.0031678676605225 s\n",
      "average reward: 1.0\n",
      "episode: 7700\n",
      "took 0.9778590202331543 s\n",
      "average reward: 1.0\n",
      "episode: 7800\n",
      "took 0.6817851066589355 s\n",
      "average reward: 1.0\n",
      "episode: 7900\n",
      "took 0.6497881412506104 s\n",
      "average reward: 1.0\n",
      "episode: 8000\n",
      "took 0.27393627166748047 s\n",
      "average reward: 1.0\n",
      "episode: 8100\n",
      "took 0.6872310638427734 s\n",
      "average reward: 1.0\n",
      "episode: 8200\n",
      "took 0.5856671333312988 s\n",
      "average reward: 1.0\n",
      "episode: 8300\n",
      "took 0.6466550827026367 s\n",
      "average reward: 1.0\n",
      "episode: 8400\n",
      "took 0.6402387619018555 s\n",
      "average reward: 1.0\n",
      "episode: 8500\n",
      "took 0.26874589920043945 s\n",
      "average reward: 1.0\n",
      "episode: 8600\n",
      "took 0.712144136428833 s\n",
      "average reward: 1.0\n",
      "episode: 8700\n",
      "took 0.5647859573364258 s\n",
      "average reward: 1.0\n",
      "episode: 8800\n",
      "took 0.5920901298522949 s\n",
      "average reward: 1.0\n",
      "episode: 8900\n",
      "took 0.6205787658691406 s\n",
      "average reward: 1.0\n",
      "episode: 9000\n",
      "took 0.2531578540802002 s\n",
      "average reward: 1.0\n",
      "episode: 9100\n",
      "took 0.6799130439758301 s\n",
      "average reward: 1.0\n",
      "episode: 9200\n",
      "took 0.6141488552093506 s\n",
      "average reward: 1.0\n",
      "episode: 9300\n",
      "took 0.5774872303009033 s\n",
      "average reward: 1.0\n",
      "episode: 9400\n",
      "took 0.28205227851867676 s\n",
      "average reward: 1.0\n",
      "episode: 9500\n",
      "took 0.5367002487182617 s\n",
      "average reward: 1.0\n",
      "episode: 9600\n",
      "took 0.6020281314849854 s\n",
      "average reward: 1.0\n",
      "episode: 9700\n",
      "took 0.6004400253295898 s\n",
      "average reward: 1.0\n",
      "episode: 9800\n",
      "took 0.23986411094665527 s\n",
      "average reward: 1.0\n",
      "episode: 9900\n",
      "took 0.6418616771697998 s\n",
      "average reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "debug=False\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "# training loop\n",
    "reward_times = []\n",
    "num_episodes = 10000\n",
    "average_rewards = []\n",
    "t0 = time.time()\n",
    "log_running_reward = 0\n",
    "log_running_episodes = 0\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "\n",
    "    observation, info = env.reset()\n",
    "    current_ep_reward = 0\n",
    "    if i_episode % 100 == 0:\n",
    "        print(f\"episode: {i_episode}\")\n",
    "        print(f\"Time per 100 episodes: {time.time() - t0} s\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        if i_episode > 0:\n",
    "            average_reward = log_running_reward / log_running_episodes\n",
    "            log_running_episodes = 0\n",
    "            log_running_reward = 0\n",
    "            print(f\"average reward: {average_reward}\")\n",
    "            average_rewards.append(average_reward)\n",
    "\n",
    "    for t in range(1, max_ep_length + 1):\n",
    "\n",
    "        # select action with policy\n",
    "        action_mask = info['action_mask']\n",
    "        action = ppo_agent.select_action(observation, action_mask, debug)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # saving reward and is_terminals\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done)\n",
    "\n",
    "        time_step += 1\n",
    "        current_ep_reward += reward\n",
    "        \n",
    "        # save time till reward\n",
    "        if reward > 0:\n",
    "            reward_times.append(env.t)\n",
    "            log_running_reward += 1\n",
    "\n",
    "        # update weights of agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent.update()\n",
    "\n",
    "        # break; if the episode is over\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    i_episode += 1\n",
    "    log_running_episodes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAp6ElEQVR4nO3dX6hlaVrf8aeabTtk6OpWaJCmC82J2YfADF54Ds4hMgFhGJBAbnITEgJhNHchoGQ6iojoRVSSm3ihIbnqSUII5CaIGUexexjpU62bYRwH2r2RjXQP5Z9oZ6qrx1bqWCsXi3Omumr/WWu97/u8v+dd3w80QzG1zvurZ71r73evvd7n3Oq6rjMAADBbz9QOAAAA6mIxAADAzLEYAABg5lgMAAAwcywGAACYORYDAADMHIsBAABmbjHkLz169Mju3btnzz33nN26dat0JgAAkEHXdfbgwQN76aWX7Jln9n/+H7QYuHfvnt25cydbOAAA4Oedd96xl19+ee//P2gx8Nxzz938sNu3b+dJBgAAinrvvffszp07N+/j+wxaDFx/NXD79m0WAwAABHPsK34eIAQAYOZYDAAAMHMsBgAAmDkWAwAAzByLAQAAZo7FAAAAM8diAACAmWMxAADAzLEYAABg5lgMAAAwcywGAACYORYDAADMHIsBmJnZ1dWVbTYbu7q6qh0FgBOue1xjMQC7urqyi4sLOz09tYuLC14YgBngusfjWAzAttutrVYrMzNbrVa23W4rJwJQGtc9HsdioFFjbv+dnJzY2dmZmZmdn5/byclJ6XgAKpty3fO1QrtYDDRo7O2/xWJhl5eXtl6v7Y033rDFYuGUFEAtY697vlZo262u67pjf+m9996z559/3u7fv2+3b9/2yIUEm83GTk9Pb/68Xq9tuVxWTAQgOl5XYhr6/s2dgQZx2x9AbryutI37wQ26vv233W7t5OSE2/4AkvG60jbuDDRqsVjYcrnMdsHy4BAQT+7rNvfrCnSwGMBRPDgExMN1izFYDOAo9iMD8XDdYgwWAziKB4eAeLhuMQaLgaBSvgsce+zUPgQezxl41gFtU59LEa5brqm4WAwElPJd4NRjxz445PF9ZY06oE3qcynCdcs1FVw3wP379zsz6+7fvz/kr6Ow9XrdmdnNf+v12uVYr4weY3jVATGoz6UI1y3XlKah79/cGQgo5bvAqceOvf3n0fe8Rh3QJvVrSvm6zXEsBORcWcDPw4cPu/V63T18+LD4sQ8fPuzOzs46M+vOzs5GHTd0HI8xch6L9qhfU4rXbc5jUcbQ929+NwGO8uhJTt9zzAnXFLzwuwmQjcftP24xYk64pqCGOwMY5OrqqnhPco8xABVcU/DAnYGZi9iTnN+nAGVcU1xTLWMx0CD2+1ID5MV8ogatYzHQoGM9yb1W9zU/RQzpy67YNQ671T5XCn3+a1+3CjVAOSwGGnTowSGv1X2JcXLuy1buGocPUzhXHn0zUvLlcmgcHkhsXM59itCxb79vhE5mu+Tel91S17jWqZwrj74ZKflyODYOfQTiGfr+zWJgZh5/kTo/Py/WiGTKOJ5v3h51mDoGPiz3XMo1xiElFxdq1y20sRjAXoqdzI6NUeJFSrFrHHZT72Z5KMOu+dpqB0LooQMhslHpllZ7zzQd3WJQOU+H5qvKNYX20WcA2ah0S/PYl30ID1DFoHKeDs1XlWsKuMadAQxCt7RehIyIcZ64puCBOwMz59EtLWWMXcdG6JYWIWPuMSJkfFKJu0hcU/TNaBmLgQYp7MuOnM9LhDpEyOhBvQ7q+RBAzqcRoUFlX3bUfF4i1CFCRg/qdVDPh3rYWjhj6vuylff4p26rUsuYuiVTdS55nievjK1eU6iLxcDMqe/LVtzjn9o1TjVjrQVOrZ4UkTO2dk2hPhYDGCzC7b8It0EjZCwtQg0iZPQQISPSDX3/5gFChNiPHGFfdoSMpUWoQYSMHiJkhB/6DMDMYuxHjrAvO0LG0iLUIEJGDxEyIs3Q928WAwAANIqmQ6hOvUFJxGY6JZDRb4wU6vkQG4uBRtV+4VBvUKLSpIXz9K0c++qgcq5qUslXe76ioJxPI0JD6tarHNSfVFZ4opzz1DtWB4VzVZtCPoX5ivHYWjhjJV44FJu0pByv0KQl6nmaMs4hYxZNSg1/WpuvxygsSDAei4EZy90pTLlJS8rxtZu0RDxPKeMM+Xn76qDW8KfV+Tr059GBMA4WAzM35YVj399XuU0bIeNYUz657TvG65PbkE/yuf5NJfLl0Mp8zfk6AU0sBjDYsU8QHp8Ijo0RIaOHQ3XwyndoHIXvlRXmQoT5qnCuUB6LAQxW4hPEFKmfpGpn9FDiU/kUte9OTM3nNUaE+apyrlAWiwEMpvCJ95gIGT2o10E9n5cIdYiQEemGvn/TgRBmFqMtaYSMHtTroJ7PS4Q6RMiINHQgbFxK849dxy4WC1sul1lfEHI3KMmdMWpXO/U6RJhLHmOonyez3Rlzv7YgBhYDAaV0I/PqZKbSMW0futr1yOg3RooI1616DXFEzu8c4CPlwR+V7We1qWztqo2MfmOkiHDdqtdwroa+f3NnIKCU30M+9dixt/+mjJN6i3HM8R518Kp1yrGtZlQcI+V45es2x7EQkHNlAT8p25K8OpnR0c23a1yEDoTKc4n5Om2cXMeiDLYWIpsIt2kjZCw9BreS44wRISPawGIA2Uzdjzz1k9aUPc9Tjk/5pKXY5dDjPNXKOAbzNU9GtIHFALJSvKWecnyNW6hDtfYVUM5jS43BfEWraDo0c7WbiWw2Gzs9Pb3583q9tuVy6Z5jH5V8nKcedThMJV/t84TxaDo0Ywr7fdWfLFbIx3nqUYfjFPIpnCeUw52BBvEpYpja+ThPPeowTO18KucJ43BnoCFR90yrt2PN3Yp17PE19vjvUvs8MV+HYb6iqJwPICC/VvdMjxVhDOW9416Yr3HGYL7OA7sJGhFhP3KEjB5jRMhYWoQaRMjoMUaEjEjHYqAR7JnWHiNCxlpb4Fqar14Z1etAr4N4WAw0hD3TmmNEyNjqrWTP8+SVUb0Ota4ppGExMGPqt+a4PdmLUIcIGT1QB/182I3fWjhjCnuSD/HIp14Dsxh1iJDRA3XQz4c09BloVO09ycd45FOvgVmMOkTI6IE66OfD04a+f7MYAACgUTQdQlY0Dump18ErH3WIgTpgKBYDMLPDLxoqPclrv7ANqYNHxn1jeJ2nY+PUrMGQfF6Yrwgl59OIiOnYliGFp4gVOpkdq0PtrnNe5+nQOLVrcCyfF+YrVLC1EIONedEo1UAlNeMUuRuo1N5+5nWeDo1TuwbH8h3CfGWrYItYDGCwIS+eHg1UUjNO/Xm5Gqh4dFs7NobXedo3jkINDuUb8jOZr2gJi4GZm/JimLNL2JBPb2PHy/lvKvWpyKPurX2CnXKM93z1yrjvmMjzFXWxGJgxhe8CD33qUPheWeFTkfp5qpFBtQ615yznCVOxGJgxle8CvT/ljB2j9qcc9fPkJUIdFOYs5wlT0I54xlTahi4WC1sul091KlNp7bovnxf18+QlQh0U5iznCSXRgbBR6m1Dae3ai5DRQ4Q6MGf18+FpdCCcudyfInI3J9mVL3WMJ48v8UnKow4ponYgjFCHJzPmnq+7xkilfp6gg8UAjvLo6JY6RoSMpal0IKwtwlyIkBEzk/MBBLRJ4eGpFjKWptCBUEGEuRAhI9rAA4SNS7n9N/bYqQ8OjRkn9eGkKcd71KHEreSc+aZkpA7tztcp4+Q6FpXlXFnAR8p+3xKdzHKNk7p1aszxHnVI3ZftUUPq4DdGyvHK122OY1EOfQYalnL7j1vJvQi3aSNk9BgjQsbSIly36jWcKxYDDUvpRubVyUyhY9ohHvlSx4iQ0WOMCBlLi3Ddqtdwroa+f9NnIKiU/b5ee4XV9yRH2DceIaPHGBEylhbhulWv4RwNff9mMQAzi3ERk9FvjBTUoEdGKKDpEAaLsB+ZjH5jpKAGPTIinJzfOSCmCA/+kNFvjBTUoEdGqKDPwMyp7ctOPVZ9b7tXRvU6KO/xb60OqcfWmEsQlnNlAQ2q+7JTj1Xf2+6VUb0Oinv8W61D6rGecwl1sLVwxtRv1arni5LRY4wIGT3GUM+ong/1sBiYsSn7fVM+xXjtR576KcZzb7tHRvU6eMwlz/kaIWOEuYQ6WAzMnNrt6tRjPW7TRsioXgfl29Wt1SH12BpzCf5YDGCwCLf/yOg3Rgpq0CMjVLCbAIOl/gY2D2T0GyMFNeiREdHQgRBmFqMTGRn9xkhBDXpkhALaEQMAMHO0I0Z16g1K1PN5oQ499Tqo50NsLAYa5fHCcWiMY33P1fMpZPQYgzp86/9TroN6PjQg59OI0ODRKezYGIeeVFbPp5LRYwzq0FOvg3o+6GJr4YwpbO861KBEPZ9KRo8xqENPvQ7q+aCLxcCMeXQKGzLGvgYl6vmUMnqMQR2+9XeU66CeD5pYDMzclG5kYzuLeXZLm3KMdwdCr4zqdVD9N7VYB+/x6EAYD4sBDBbhu0Ay+o2Rghr0yAgVLAYwWITvAsnoN0YKatAjI1TQjhiDRWhLSka/MVJQgx4ZEQ0dCGFmMdqSktFvjBTUoEdGKKADYeNSmn/sOnaxWNhyucz6gpC7QUnujCUaqDyZMXUMj3PlcZ5y14H5mkfuc0VTorhYDAQ0pBtZiWO9MnrwyJc6RoSMHmNEyFhahOtWvYY4IucDCPCR8uCP10ND6g8nRXjQLUJGjzEiZCwtwnWrXsO5YjdBw1Kaf0w9dsp+5LHjeO4D96hDapMWjxpSB78xUo5Xvm5zHItyWAw0zrM5ydT9yFNf7KbseZ5yvEcdar1hlDpPU8dprQ6tztcp4+Q6FmWwGEA2EW7TRshYWoRbyR4izIUIGdEG+gwgmwh7xyNkLM0rH3VgvqI99BnAIBH2jkfIWJpXPurAfEUMQ9+/WQw0Sv1FgBfCXoSMpf3pn/4Pe+utf2JmZj/4gw9l68Cc1c+Hp9F0aMbU9/uyb7wXIWMJf/7n/9tef/3WzX/XCwEzs9/6rW+XrANzVj8f0rAYaNB2u7XVamVmZqvVyrbbbZUc+7qReeQbMkbtbmnq52mqN7/+pn3u9z5nb379TTMze/fd3/zQm//XvvaP9h777LOPJOugMGeZryiJxUAAY18Epjw4lPuF5tCniKkPNo3JeGyMUp9ycmbMMcaQn5WzDq/8xiv2w5/7hN35f//cPvjDT9jrr9+yr371U4OP/+xn9earmc81dWgM5iuKy7k1AflF2DO9y7FtTbX3tpfYdqW8d3yfnHW4+87d7u/9B+tee23cf9f/LuX56pVx3xjMV0xFn4FGqOxH9uxkNjXjGCU6uimcq5odCF/9yqvdi/9u2Jt/CuZrO/MV5bEYaIRHi89jY9ToZDY249SfmfNTTu1zVbsD4d137nYf/bmn3/wv374c/w8dOD7zdVgGxfkKHywGGuLR4rP2J4gharc6LfGJdArPW8m7HBrnJ7/wr28WAb/wv6x75TdeKZKB+Xqc+nyFDxYDyIbVfU+9Dl75Dt+d+MbNYuCLb36iyPgp+eaEOqDrhr9/03QIg9BspKdeh9odCK+u7ttv//YLZmb2Hd/xafu+7/t8sQxT8s0NdQBNh2Yu93aexWJhy+Uy2wuKx3ajEmOo12FXvtQxdh0fsQ6pIs5Z9fMEHSwGGqTeKYxubr0IdYiQ0QN10M+HRDm/c4AGlQeo9mFLUy9CHcYe//gzA1/5yqddMnqIcK5KU8+H3fgVxg2J0IFQrZNZrW5pahlr/qrd7vjjSJPH8DxPXhnV60AHwsblXFkgvwgdCFU7mXl3S1PNmLq1a8zxH3zwf2/uDPzKr9xuZr56ZVSvg/c1hXRsLWxEhNuTETJ6jBEhY0mPHj3q3nzzn94sBn7mZzRr0Mp5og4Ygq8JGpF6m9djjAgZPcaIkLGkP/qjn7a//Mv/ZmZmf/M3Zn/wB6eSNWjlPFEH5ESfgQCm7BUee0zqfmSP/cwRxvCou+Le8bff/ve23f6bmz+/8MIv2Mc+9mPMV/Ex5jpf52To+zeLgQZdbwFarVZ2dnZml5eXXISCWjlP9+79F9tsfvTmz9/7vf/RXn75Xw0+vpU6tI7zFBNNh2Zsu93aarUyM7PVamXb7bZKDvWniGvna+E8/dmf/U/bbP7lzZ+/53t+dtRCwKyNOnionU/lPKEMFgMNUvieTr1BiUK+6OfpL/7i/9hbb/0z658NM3v55R+z7/7unxqdIXodPCjkUzhPKIevCRpV+3u6zWZjp6enN39er9e2XC7dc+yjki/qefrGN75kX/3qp+3Row/MzOy7vuszdnr6n+3WrVuTckStgxeVfLXPE8bja4JAWuyhTwOVYXL/LgGP8/T++79nv//7//BmIfDii//YTk//0+CFgOLvOmC+DhP1dz5ggJz7FDFehKYcNFDJk7H0GB7nqeu67itf+eEPNRb6679+v3jGMZiveTJ6iJAxOpoOBRGhKUeE5iQRMpYew2sufelLy+6116z79V+37iMf0csYYYwIGT1EyBgdTYcqUr/953ELdew4NRqoKN5KTqmD11x69tlvM7O+sdDHP66XUXmMlOMVr9saGflaoZCcKwvo3/7zupWs3kNf+VZySh08ztPv/M7Hutdes+711/+WbEbFMVKOV75uPTPytcJ4fE1QifrtP6/bcuq3/9TPk5cpGa8XA1/84kcdEnKuui7Gdct50sTXBJWo9/v22iusvidZ/Tx5IaPfGCkiXLecp9joM1CAek9yr73C6nuS1c+Tl7EZf/d3P27f/ObX7JlnPmqf/OT7Dgk5V2YxrlvOkx5+N0FDuMB6ETJ6qF2HY4uB2vlURKgDry3to+lQIzzakCq0Oj0mQkYP6nVQz+clQh14bcHjWAwIOLRVxuOXgwwZw2M7T2odamf0cKwOHvmubyZ2XffUOCq/zKb2XIgwX+f02oIBcj6NiPGObZV5/P8/Pz8vvl1n1xgKXeMiZJz6M6du/XqyDqVq8MEHb3d//Mevdm+99S+6y8u/fdN98Nd+7elxPObrkJ9Vey5EmK9TzlXO+TokI9KxtTCIIVtlau+ZVtkyFCHjGLn3ZU/Nd/du1736av+/Xdd1f/VXX+/+5E/+a/fWW5/pLi//zs2b/5P//fIv7x6ndttclbkQYb7W7nXAVsHyWAxUlPNT+RQl37Rq3Z0ocXzuTzljx1A4T5/9bNd953fe637oh/579+M//qPdr/7q39375t83Gvr27stf/gfdT/zES90LL+SZsyXftJiv+V5bSrxxe9Rh7lgMVFKjk9mhDLkWGLXvTuTOWOJTztgxap+nu3e77kd+5N8eefN/tvvylz/Zbbc/3b377mvd1dUHo8cZkjn3rWTma56M+zLkmq/XP5cOhOWwGKhE5bZX7dWzSh32iXibNrdXX+26T33q1Q+9+X/hC9/Wff7zf7/bbn+qe/fd3+yurr7pkqX2rWTm6zC8rsTDYqCSUqvnaNTr4JFPvQZ373bdiy++3f3SL110n/nMT3bf//1f6D7ykfdvnh1QwbnSz+eFOow39P2bpkMF0GSjp14HGq6YvfKK2S/+4of//PM/Xy/PPpwr/XxeqMM4dCAcKMLE4oWwF6EOETI+6c03zTYbs+XS7Ad+QC9fiTEiZPRAHXoRMk41+P07522GaCI8jOKRkTrkGSNCxtIi1CBCRg/UoRchYwqeGRggwsMoPDzVi1CHCBlLi1CDCBk9UIdehIwpWAwMEOFhFB6e6kWoQ4SMpUWoQYSMHqhDL0LGFCwGBpqyVcZzf7FXRu86tPhvUs3IvylORq6pGOc2EhYDhfB9ZfoY6vm8RKhDhIwe1Ougns9rjAhzyRuLgUL4vjJ9DPV8XiLUIUJGD+p1UM/nNUaEueSNxUAhfF+ZPoZ6Pi8R6hAhowf1Oqjn8xojwlzyRtOhgtjjnD6Gej4vEeoQIaMH9Tqo5/MaI8Jc8kTToUwiTH4P1KGnntErH3VIxzXVow5lDX3/fsYxUzhXV1d2cXFhp6endnFxYVdXVyHHSEUdeuoZvfJRh3RcUz3qICTndw6tifDAjAeVOtTe/qN+rrzyUYdhDs1XlWuqNupQHg8Q7jHmDWXqwyhqY6Qeq1CHEluGPOrguWfaay5Rh2E/69B89ahhq68timMoYzGww5Q3lJSJpzRG6rG165B7de9Rhxp7pr3mEnU4LPedLuXr1jOj8hiqWAzs0MotqZQXmqi3knOv7tXPk1JGjzEi1MHj7kRKvhyOjRPhPEUYwxOLgR1yX6CqYxxa2XrkKzVOztW9+nlSyegxRoQ6eNydSMmXy6FxIpynKGN4YjGwh8d3QbXHSFnde2UsTeWBxNRPUrUzeowRoQ4KnxZrX7cRzlOkMbywGJix1la2U0SoQYSMHiLUIULG0qhBTHQgnLk5N9m4FqEGETJ6iFCHCBlLowbx0HQok6urK9tsNkUbVZQYY7FY2HK5zHbBRqxD7hqY6Wf0OE8lxolQhwgZS48R4ZqqNUZ0LAYOoDtWjzr01DPSgbCnns+Ma+oadRCS8zuH1rCNpUcdeuoZVbaf1aaer+u4pq5Rh/J4gHAPj73CamOkHksdpmdMfSpZsYbUIf1YjxpSB78xlLEY2MFjr7DqGKnHUofxGVPyTT3eq4bUIf1YjxpSB78xVLEY2KGVW1IpY7R0K1m9DqljRMjoMYZ6RvV8XuO0UofWvlZgMbBDK7ekpt7+SznWM+NQ6nVIrYHyXKIOeY4tPUaEOnjMJc/5qobFwB6t3JIae5GnHFsj41DqdUitgeJcog55jy01RoQ6eMylGvNVCYuBDLgl1VPJWPsCVanDPhFuJXtQycd8PY7X2PKGvn/TZ+CAk5MTOzs7MzOz8/NzOzk5CTlGKoWMCnuFFepwiFc+6nAc83UYXmN10I74CI/2mxFafNbOuNls7PT09ObP6/Xalsule47adTjGKx91OIz5OhyvsWXNth2xR/vN1DGePD5Ci8/cdRh77JTV/Rxb0nrM133jpGitbe7UT6O5ryn182T2dMY5zlcJOb9zqM1jf2jqGBEylh5D+cFMT+rnKUpGD6oPuuU4tqUxImT0NssHCCM8jBIhY+kx1PN5iVCHCBk9qNdBPZ/XGBEyepvlYkB5v2+kjKXHUM/nJUIdImT0oF4H9XxeY0TI6G2Wi4Gum3Zrbuz2H889014ZvevQ4r9JNSP/pjgZuabaPbe1zHYxMEaE7374DqwXoQ4RMpYWoQYRMnqgDr0IGVOwGBggwnc/fAfWi1CHCBlLi1CDCBk9UIdehIwpWAwMEOG7H74D60WoQ4SMpUWoQYSMHqhDL0LGFEPfv2ffdChCMwqacvQi1CFCxtIi1CBCRg/UoRch41RD37/DLQYinLQIGT2o14EXwh4Z/cZIoZ7PS4Q6KGVssgOhQr/vYyJk9KBeB4986jUwI6PnGCnU83mJUIcIGXfK+Z1DaUMe9Ki95UPlYRT1OnjkOzSGysNT6ufJC+fq8BgRzpOHCHVQyXgtzAOEYybXsQc9SmwRmbL/dOzDKLkvMPU6KGxpmvrQEPN12jhDM+Q6V7nrUHvORjhPKT831zWVY4wxGWrN1zFCLAamTC7PFdnUyT91cue6wNTrEPWTHvM1bZx9cp+rEnVQmLMRztNYua+pXGMcojJfhwqxGCj5YphjRabwAnAs4y7qdVD4VD6Feh28bk+WfNPKca5Kv2nVujsxVsk3rVzXbcTX2Ajz9XEhFgMlXrBzrshK5DuUIeftSfU61P5UPoV6HTzm67FxvO5OTM2X+nNr3p0Yq8RrS+7rNuprbIT5ei3EYqDr6j6Qov7Q0NCMqVTqcIjKQznqdfDKV/vuxNR8XiLUYU6vLbXrkJIvVZjFQE1en6RSKKycFUTI6EG9Dur5vESoA68tvQgZU9CBcCCl5hD70HClFyGjB/U6qOfzEqEOvLb0ImScqsmmQ2b9SdtsNtkaOSwWC1sul1kngEfGlDF2HRu1Dily5/MaQ70OEeaSxxjq58ks5mvLHK8pFzlvM5Q29aEcTx4ZU8bwqqH6uVI/T17I6DdGigjXLeepp5axyWcGFB70OEbloZya+TzHmUr9PHkho98YKSJct5ynnlrGMIuBqdt1vLpPpWylUdyP7FVDjzqkHO9Rh1bna4SMimOkHK983XpmZL6OF2IxMOV2SsqJ8brtNXVye+1H9qqhRx1SjveoQ2vzNUJG5TFSjle8bmtkZL6OE2IxoH5bST2flwh1iJCx9BjcSo4zRoSMHtTroJ5viBCLgZRbUh5jKN/28qR+nqJkLD1Gy7eSx4gwRoSMHjxuqc99voZYDHRd/e5TuY/1uO1Vg/p5ynF8C2O0eCt5ighjRMjoQe0roJzHKowx26ZDtZtHbDYbOz09vfnzer225XLpnqN2HY6h2Umvdkbm63DM2fr5mK/jNdt06JCrqyu7uLiw09NTu7i4qNLw4eTkxM7OzszM7Pz83E5OTtwzKNThEI986jUw08jIfB2GOauRj/laUM7bDLWpPDBT+9acSh32aeGhnBxUMjJfj2PO6uRjvo4T5pmBQzweFPGaWLW+B57rnmmvh+kiZiyttfnqlVG9DjXmq+Lrc7TrNvxiwONBkaljjJUyToQ6eDw0qTpGtIyltTpfvTKq18Fzviq/Pke6bsMvBlq6Ldf6PtcIGT3GiJCxtAg1iJDRYwz1jBFen5XG2Cf8YmDqrRi1MVLHiVCHCBk9xoiQsbQINYiQ0WMM9YwRXp+Vxtgn/GKg63T3d3od4zme53ePU8dTHCNCRv5NcTKq16HF177UjEpj7NLEYkBRze9+hlLP6JFPvQZdF6MOETJ6oA76+bouRkZvLAYKUf/Otuv0M7b+Hd1QEeoQIaMH6qCfr+tiZPTGYqAQ9e9su04/Y+vf0Q0VoQ4RMnqgDvr5ui5GRm+zbUfsIUIrSvWMtHbtRahDhIweqIN+PrMYGT0Nff9mMSAgwuSNkNGDeh288lGHGCLUIULGyGb5uwkiitDnOkJGD+p18MpHHWKIUIcIGWcj53cOGG/IAy+1t71EyOgxhnodVJq0cJ40xohQBx74K48HCCsac4Ede+BFYUtThIweY6jXYerDU1P2mu8bp3YNjuVTyegxRoQ6TJmztfbrR8VioJIpF1jtlXPqJwiVjB5jqNch5Y09Rw99hRocyqeU0WOMCHWY+uGJPgLDsBioJPcF5vFpr8b2s5yfRmuOES3jk5ivWhnV69DafJ0DFgOV5J781z+z9Ke91FtvHqt7tTGiZtyXgflaN6N6HVqdr61jMVBR7e+01FfPKrcna1PJyHw9jjmrk6/2fI1m6Ps3WwsLWCwWtlwuq+2ZPTk5sbOzMzMzOz8/t5OTkyo59vHIp14DM52MzNfjmLM6+WrP11bRdKhR6o086ObWi5DRQ4Q6MGf18+FpNB0K5OrqyjabTdaGG7lXz7kz7sqXOsaTx5f4BOFRhxQl5pLHOBHq8GTG3PN11xip1M+Tmd+cxWEsBiqL0IHLI2PqGBEylkYHwl6EuRAho4cIGWcj5wMIGE/loZxDIjw8FSFjaSodCGuLMBciZPQQIWN07CYIosZWGa+9wuyZrrf1q1YHwlxjpBzPfE3L6Pm0PlsFy2MxEEiti6/kXmH2TKd3S1Pd2z52nFbr0Np8TRknBVsFy2IxgJ24ldyLcJs2QkaPMSJkLI3rFlPRZwA7ee0VVtmTvE+EfeMRMnqMESFjaVy3KI0+AzPktVdYfU9yhH3jETJ6jBEhY2lct5hi6Ps3iwGEEeFFijctanAtQka0j6ZDaEqE/cjsHacG1yJkBB7HYgAhbLdbW61WZma2Wq1su91WyXGoW5pHRpU67KNSg9pd7dTPE/AkFgOoYuyL9ZQHm3K/IRz7tOeRsUYdxhw/9QG0nGOU+lSuVgcgq5xbE4AhIuxt32XItiu1veNz3ONfYnucah2AY+gzAFkq+8a9OrqlZEyVWgeVjGOU6LwXsQ5A17EYgDCPFqTHxvDq6JaSMYfUOihknPozc34qj1oHYOj7N1sLUUXt7WebzcZOT09v/rxer225XBbJcUiEOtTO6IE6oFX0GQAOuH7IbLVa2fn5ub3xxhuzfPGlDj3qgFaxGACO4FNYjzr0qANaRNMhNCf3tqvFYmHL5TLrC7/H1jD1OkSsgVnMOgC5sBhACBE6utF9jxpci5AReByLAYQQoaObSve9mqhBL0JG4HEsBhBChF+tyq/apQbXImQEHscDhAhj7ANeNX5trkdG9Tqo/psi1AHIjQcI0ZwxD3ilfmc79XiPjOp1GPsgnuoY3hmBqnJ2MAJUpLZ2baX9LHXIMwatghHV0Pdv7gygSanf2Sp/9+3x2/NSjvf4TYxjRZgPQE08M4Bm1XhmoPQYj3fKOzs7s8vLy6PHedZhSr4cGYeIMB+A3OhACBRQ+w1B5Xcq7KOSr/Z5AlTwACGQmUIjGfXb1Qr5FM4TEA13BoCB+NQ7TO18KucJUMCdAeAIjwfdUvvT7zpevYf+rnwl6rCPx4OZQGtYDGCWpu4bv7y8tPV6PehX3NbqddDaGGOPH3uecmQEouNrAsySx63k1DEiZPQYI0JGQBVfEwAHsMc/LSN1ABqTs4MREMnDhw+79XrdPXz4cPDfPzs768ysOzs7G3Tc2DFSjp+Sb0pG6gDEMfT9m68JgIHUbyV75aMOQBx8TQBkpn4r2SsfdQDaw50BYITae+iP8cpHHYAYaEcMBMCbVo86AGXwNQEgjr3tPeoA1MdiALPl0XHu0Bjb7dZWq5WZma1WK9tut8VyHFK7896QOtQ+V0DrWAxglhQ67ym0zS1Rh9x7/BXOFdC8nPsUgSjW63VnZjf/rdfrKmN47PFPzThGiT3+KucKiGjo+zd3BjBLKp33xv7SoWO31Gt3IJz61cehOtCBEHCQc2UBRBKh896hDOfn5x/6uQodCA/lS0EHQmAaOhACmal0ttu3DU+lA2HtbYIq5wlQwNZCIDOVW8n7bqmrdCAc+9VHbirnCYiEOwPACLU/9R5DB8Keej7AC3cGgAJyf+rNvbd9V77UMXYdH7EOAPZjMQBUEmH/fISMANKxGAAq8ehAmDpGhIwA0rEYACrxeNAtdYwIGQGk4wFCIKOxD65NedDNYwzv8bz/TcBc8AAh4GzKd99jH3TzGCPl+Knf/3uMAWA/FgNAJny/Tg2AqFgMAJnw/To1AKLimQEgI4/vstW/L6cGgA6eGQAqePK779zNdHaNkSpCw58nM9JUCMiLxQBQSIQH3cgIwIzFAFBMhAfdyAjAjMUAMMqYW+pTH3RLuW0/9thWM5b4egZoGYsBYKCxt6sXi4VdXl7aer22N954o/ge+qk9CFrLyNcKwHjsJgAG2mw2dnp6evPn9Xpty+XSfYx9T9J75BsyzqEn/VVqCMwFuwmAzBT20B/61Ou1//7QOMc+lSvUEMDTuDMAjFB7D33Kp3KPjCl3NjzyAXMz9P2bxQAQyPUn79VqZefn54O/5/eing+Ym6Hv31ylQCDXD9OpfupVzwdgN54ZAAqiA2EebBUEymIxABQSYYsbGQGYsRgAionQOY+MAMxYDADFtNrdL0pGAMOxGAAKabG7X5SMAMZhayEgJKV7nkoHQoWMAHp0IAQCSrkl7nXLv0ZGAGVxZwAQk9I9b+yxjzcJOjs7s8vLy8HHeWUEMB0dCAEcxW17oG18TQDgKG7bAzCjHTEwa7QPBmDGnQEgHPX2wbQOBuJhMQAEot6aVz0fgN1YDACBqLfmVc8HYDcWA0Ag6g/8qecDsBuLASCQqe2DU77DH3M8rYOBmFgMAMGMeeAv9Tv8qb9LIOcDiQDKYzEANCz1O3yeAQDmgcUA0LDU7/B5BgCYB+7jAQ1LbSpEUyJgHrgzADRk18N+qd/h7zqexkJAW1gMAI3wavhDYyGgPSwGgEZ4PezHQ4VAe1gMAI2Y+rDf2Fv+PFQItIfFANCIqQ2JpvQRoLEQ0BYWA0BDxj4sOPWWP42FgLawGABmjFv+AMzoMwDMGn0EAJixGABm7/qWP4D54msCAABmjsUA0BCvzoB0IATawmIAaAQdCAFMxWIAaAQdCAFMxWIAaAQdCAFMxWIAaAQdCAFMxWIAaAgdCAFMwWIAmDFu+QMwo+kQMGt0IARgxmIAmD06EALgawIAAGaOxQAAADPHYgAAgJljMQAAwMyxGAAAYOZYDAAAMHMsBgAAmDkWAwAAzByLAQAAZo7FAAAAM8diAACAmWMxAADAzA36RUVd15mZ2XvvvVc0DAAAyOf6ffv6fXyfQYuBBw8emJnZnTt3EmMBAABvDx48sOeff37v/3+rO7ZcMLNHjx7ZvXv37LnnnrNbt25lDQgAAMrous4ePHhgL730kj3zzP4nAwYtBgAAQLt4gBAAgJljMQAAwMyxGAAAYOZYDAAAMHMsBgAAmDkWAwAAzByLAQAAZu7/A+5orzbvoXbAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "observation, info = env.reset()\n",
    "start_position = env.coordinates\n",
    "trajectory = [np.array(start_position)]\n",
    "for t in range(1, max_ep_length+1):\n",
    "    # print(f\"t: {t}\")\n",
    "    # select action with policy\n",
    "    action_mask = env.get_action_mask()\n",
    "    action = ppo_agent.select_action(observation, action_mask)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # saving reward and is_terminals\n",
    "    ppo_agent.buffer.rewards.append(reward)\n",
    "    ppo_agent.buffer.is_terminals.append(done)\n",
    "    trajectory.append(env.coordinates)\n",
    "\n",
    "    time_step +=1\n",
    "    current_ep_reward += reward\n",
    "    # elif done:\n",
    "    #     # print(\"done but no reward\")\n",
    "    # update PPO agent\n",
    "    if reward == 1:\n",
    "        break\n",
    "\n",
    "small_s = 2\n",
    "big_s = 10\n",
    "plt_size = 50\n",
    "\n",
    "trajectory = np.array(trajectory)\n",
    "reward_position = (0, 0)\n",
    "positions = np.array(list(env.graph.keys()))\n",
    "plt.scatter(positions[:, 0], positions[:, 1], s=small_s, c='k')\n",
    "plt.plot(trajectory[:, 0], trajectory[:, 1], c='y', linewidth=small_s)\n",
    "plt.scatter(start_position[0], start_position[1], s=big_s, c='g')\n",
    "plt.scatter(reward_position[0], reward_position[1], s=big_s, c='b')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_agent.save('pen_world_agent.pth')\n",
    "ppo_agent = PPO.load('pen_world_agent.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pen_world",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
